{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RANDOM_SEED = 43\n",
    "\n",
    "TRAINING_RESUME = False\n",
    "RESUME_EPOCH = 12\n",
    "MODEL_SAVE_PATH = 'model/'\n",
    "RAW_DATA_PATH = 'corpus_hw211.txt'\n",
    "TEST_DATA_PATH = 'hw2.1-1_testing_data.txt'\n",
    "\n",
    "RESET_AND_TRAIN = False ###### Warning (If you only want to predict on test, you must turn this off (False)) ######\n",
    "COLLECT_WORDS = RESET_AND_TRAIN\n",
    "TRAIN_WORD2VEC = RESET_AND_TRAIN\n",
    "EMBEDDING_REBUILD = RESET_AND_TRAIN\n",
    "\n",
    "WORD2VEC_DIMENSION = 128\n",
    "\n",
    "LEARNING_RATE =  1e-3\n",
    "BATCH_SIZE = 1024\n",
    "MAX_EPOCH = 50\n",
    "INIT_GRU = True\n",
    "\n",
    "ENCODER_OUTPUT_SIZE = WORD2VEC_DIMENSION\n",
    "DECODER_HIDDEN_SIZE = ENCODER_OUTPUT_SIZE\n",
    "TEACHER_FORCING_RATIO = 0.5\n",
    "GRU_NUM_LAYERS = 4\n",
    "GRU_DROPOUT_RATE = 0\n",
    "EMBEDDING_DROPOUT_RATE = 0\n",
    "\n",
    "# for logging\n",
    "CHECKPOINT_NAME = 'auto_encoder.pt'\n",
    "\n",
    "# %% [markdown]\n",
    "# # Seq2Seq\n",
    "# %% [markdown]\n",
    "# ## Prepare data\n",
    "# %% [markdown]\n",
    "# ### Set Random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f39e40af510>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Training data\n",
    "# %% [markdown]\n",
    "# ### Read training data\n",
    "# %% [markdown]\n",
    "# Currently, we only use \"train.txt\" to train, validate and test our Seq2Seq model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def read_dataset(path):\n",
    "    \n",
    "    with open(path, 'r', encoding= 'utf-8') as f:\n",
    "        data = []\n",
    "        i = 0\n",
    "        lines = f.readlines()\n",
    "        for i, line in enumerate(lines):\n",
    "\n",
    "            # Doing nothing, just insert directly.\n",
    "            sentence = line.strip()\n",
    "            if i > len(lines) - 2:\n",
    "                label = '<SOS> <EOS>'\n",
    "            else:\n",
    "                label = lines[i+1]\n",
    "                eos_pos = label.rfind('<EOS>')\n",
    "                label = label[:eos_pos+5].strip()\n",
    "\n",
    "            data.append([sentence, label])\n",
    "\n",
    "        dataset = pd.DataFrame(data, columns = ['Sentence', 'Label'])\n",
    "\n",
    "        f.close()\n",
    "    \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_dataset(path=RAW_DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train + Valid Data: 739868\n"
     ]
    }
   ],
   "source": [
    "print ('# Train + Valid Data:', len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;SOS&gt; 心 疼 你 还 没 挣 脱 思 念 的 囚 禁 &lt;EOS&gt; 9 行</td>\n",
       "      <td>&lt;SOS&gt; 他 在 你 一 段 难 忘 远 行 最 后 却 离 去 &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;SOS&gt; 他 在 你 一 段 难 忘 远 行 最 后 却 离 去 &lt;EOS&gt; 8 这</td>\n",
       "      <td>&lt;SOS&gt; 你 无 力 依 靠 在 我 这 里 &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;SOS&gt; 你 无 力 依 靠 在 我 这 里 &lt;EOS&gt; 9 玻</td>\n",
       "      <td>&lt;SOS&gt; 隔 着 刚 被 雨 淋 湿 的 玻 璃 &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;SOS&gt; 隔 着 刚 被 雨 淋 湿 的 玻 璃 &lt;EOS&gt; 1 你</td>\n",
       "      <td>&lt;SOS&gt; 你 问 了 我 到 底 爱 在 哪 里 &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;SOS&gt; 你 问 了 我 到 底 爱 在 哪 里 &lt;EOS&gt; 3 想</td>\n",
       "      <td>&lt;SOS&gt; 你 最 想 去 的 目 的 地 剩 多 少 公 里 &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Sentence  \\\n",
       "0      <SOS> 心 疼 你 还 没 挣 脱 思 念 的 囚 禁 <EOS> 9 行   \n",
       "1  <SOS> 他 在 你 一 段 难 忘 远 行 最 后 却 离 去 <EOS> 8 这   \n",
       "2            <SOS> 你 无 力 依 靠 在 我 这 里 <EOS> 9 玻   \n",
       "3          <SOS> 隔 着 刚 被 雨 淋 湿 的 玻 璃 <EOS> 1 你   \n",
       "4          <SOS> 你 问 了 我 到 底 爱 在 哪 里 <EOS> 3 想   \n",
       "\n",
       "                                     Label  \n",
       "0  <SOS> 他 在 你 一 段 难 忘 远 行 最 后 却 离 去 <EOS>  \n",
       "1            <SOS> 你 无 力 依 靠 在 我 这 里 <EOS>  \n",
       "2          <SOS> 隔 着 刚 被 雨 淋 湿 的 玻 璃 <EOS>  \n",
       "3          <SOS> 你 问 了 我 到 底 爱 在 哪 里 <EOS>  \n",
       "4    <SOS> 你 最 想 去 的 目 的 地 剩 多 少 公 里 <EOS>  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Analyze the data length (only sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentence(sent):\n",
    "    sent = sent.lower()\n",
    "    new_sent = sent.split(' ')\n",
    "    return new_sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [<sos>, 心, 疼, 你, 还, 没, 挣, 脱, 思, 念, 的, 囚, 禁, <e...\n",
      "1    [<sos>, 他, 在, 你, 一, 段, 难, 忘, 远, 行, 最, 后, 却, 离,...\n",
      "2      [<sos>, 你, 无, 力, 依, 靠, 在, 我, 这, 里, <eos>, 9, 玻]\n",
      "3    [<sos>, 隔, 着, 刚, 被, 雨, 淋, 湿, 的, 玻, 璃, <eos>, 1...\n",
      "4    [<sos>, 你, 问, 了, 我, 到, 底, 爱, 在, 哪, 里, <eos>, 3...\n",
      "Name: Sentence, dtype: object\n"
     ]
    }
   ],
   "source": [
    "trimmed_sents = dataset['Sentence'].map(split_sentence)\n",
    "print (trimmed_sents[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sentence length: 28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Length Analysis')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent_lens = trimmed_sents.map(len)\n",
    "max_sent_len = sent_lens.max()\n",
    "print ('Maximum sentence length:', max_sent_len)\n",
    "sent_lens.hist()\n",
    "plt.ylabel('# Num')\n",
    "plt.xlabel('Length')\n",
    "plt.title('Length Analysis')\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Testing data\n",
    "# %% [markdown]\n",
    "# ### Read testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = read_dataset(path=TEST_DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;SOS&gt; 在 我 们 心 中 慢 慢 流 动 的 温 柔 &lt;EOS&gt; 2 于</td>\n",
       "      <td>&lt;SOS&gt; 如 梦 如 幻 的 游 戏 &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;SOS&gt; 如 梦 如 幻 的 游 戏 &lt;EOS&gt; 9 法</td>\n",
       "      <td>&lt;SOS&gt; 街 角 有 人 祝 福 &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;SOS&gt; 街 角 有 人 祝 福 &lt;EOS&gt; 4 个</td>\n",
       "      <td>&lt;SOS&gt; 平 凡 狼 爱 平 凡 的 活 &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;SOS&gt; 平 凡 狼 爱 平 凡 的 活 &lt;EOS&gt; 6 肩</td>\n",
       "      <td>&lt;SOS&gt; 友 情 是 最 不 吝 啬 &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;SOS&gt; 友 情 是 最 不 吝 啬 &lt;EOS&gt; 12 脸</td>\n",
       "      <td>&lt;SOS&gt; 八 百 里 秦 川 &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Sentence                        Label\n",
       "0  <SOS> 在 我 们 心 中 慢 慢 流 动 的 温 柔 <EOS> 2 于    <SOS> 如 梦 如 幻 的 游 戏 <EOS>\n",
       "1            <SOS> 如 梦 如 幻 的 游 戏 <EOS> 9 法      <SOS> 街 角 有 人 祝 福 <EOS>\n",
       "2              <SOS> 街 角 有 人 祝 福 <EOS> 4 个  <SOS> 平 凡 狼 爱 平 凡 的 活 <EOS>\n",
       "3          <SOS> 平 凡 狼 爱 平 凡 的 活 <EOS> 6 肩    <SOS> 友 情 是 最 不 吝 啬 <EOS>\n",
       "4           <SOS> 友 情 是 最 不 吝 啬 <EOS> 12 脸        <SOS> 八 百 里 秦 川 <EOS>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Test Data: 50000\n"
     ]
    }
   ],
   "source": [
    "print ('# Test Data:', len(testset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [<sos>, 在, 我, 们, 心, 中, 慢, 慢, 流, 动, 的, 温, 柔, <e...\n",
      "1            [<sos>, 如, 梦, 如, 幻, 的, 游, 戏, <eos>, 9, 法]\n",
      "2               [<sos>, 街, 角, 有, 人, 祝, 福, <eos>, 4, 个]\n",
      "3         [<sos>, 平, 凡, 狼, 爱, 平, 凡, 的, 活, <eos>, 6, 肩]\n",
      "4           [<sos>, 友, 情, 是, 最, 不, 吝, 啬, <eos>, 12, 脸]\n",
      "Name: Sentence, dtype: object\n"
     ]
    }
   ],
   "source": [
    "trimmed_sents = testset['Sentence'].map(split_sentence)\n",
    "print (trimmed_sents[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sentence length: 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Length Analysis')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent_lens = trimmed_sents.map(len)\n",
    "max_sent_len = sent_lens.max()\n",
    "print ('Maximum sentence length:', max_sent_len)\n",
    "sent_lens.hist()\n",
    "plt.ylabel('# Num')\n",
    "plt.xlabel('Length')\n",
    "plt.title('Length Analysis')\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Training word2vec embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['<sos>', '心', '疼', '你', '还', '没', '挣', '脱', '思', '念', '的', '囚', '禁', '<eos>', '9', '行'], ['<sos>', '他', '在', '你', '一', '段', '难', '忘', '远', '行', '最', '后', '却', '离', '去', '<eos>', '8', '这'], ['<sos>', '你', '无', '力', '依', '靠', '在', '我', '这', '里', '<eos>', '9', '玻'], ['<sos>', '隔', '着', '刚', '被', '雨', '淋', '湿', '的', '玻', '璃', '<eos>', '1', '你'], ['<sos>', '你', '问', '了', '我', '到', '底', '爱', '在', '哪', '里', '<eos>', '3', '想']]\n",
      "Loading trained embedding now...\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "splitted_sents =  dataset['Sentence'] .map(split_sentence)\n",
    "splitted_sents = splitted_sents.values.tolist()\n",
    "print (splitted_sents[:5])\n",
    "\n",
    "if os.path.isfile('./w2v.model') and not TRAIN_WORD2VEC:\n",
    "    print ('Loading trained embedding now...')\n",
    "    w2v_model = Word2Vec.load('./w2v.model')\n",
    "else:\n",
    "    print ('Training new embedding now...')\n",
    "    w2v_model = Word2Vec(splitted_sents, size=WORD2VEC_DIMENSION, workers=4, iter=5, min_count=1)\n",
    "    w2v_model.save('w2v.model')\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Split into trainset and testset\n",
    "# %% [markdown]\n",
    "# train : valid : test = 3 : 1 : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainset, validset = train_test_split(dataset, test_size=0.3, random_state=42)\n",
    "# trainset, validset = train_test_split(trainset, test_size=0.25, random_state=42)\n",
    "\n",
    "trainset.to_csv('trainset.csv', index=False)\n",
    "validset.to_csv('validset.csv', index=False)\n",
    "testset.to_csv('testset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset: 517907\n",
      "validset: 221961\n",
      "testset: 50000\n"
     ]
    }
   ],
   "source": [
    "print ('trainset:', len(trainset))\n",
    "print ('validset:', len(validset))\n",
    "print ('testset:', len(testset))\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Collect words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def collect_words(data_path, n_workers=4):\n",
    "    df = pd.read_csv(data_path, dtype=str)\n",
    "        \n",
    "    sent_list = []\n",
    "    for i in df.iterrows():\n",
    "        sent_list += i[1]['Sentence'].lower().split(' ')\n",
    "\n",
    "    chunks = [\n",
    "        ' '.join(sent_list[i:i + len(sent_list) // n_workers])\n",
    "        for i in range(0, len(sent_list), len(sent_list) // n_workers)\n",
    "    ]\n",
    "    with Pool(n_workers) as pool:\n",
    "        chunks = pool.map_async(word_tokenize, chunks)\n",
    "        words = set(sum(chunks.get(), []))\n",
    "\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_up_word_dictionary(words, init_dict):\n",
    "    \n",
    "    ### Remove the redundant tokens\n",
    "    redundant_tokens = ['<', '>', 'sos', 'eos']\n",
    "    for token in redundant_tokens:\n",
    "        if token in words:\n",
    "            words.remove(token)\n",
    "    \n",
    "    ### Make up word dictionary\n",
    "    word_dict = init_dict\n",
    "\n",
    "    for word in words:\n",
    "        word_dict[word]=len(word_dict)\n",
    "        \n",
    "    return word_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading collected word dictionary now...\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "    \n",
    "PAD_TOKEN = 0\n",
    "UNK_TOKEN = 1\n",
    "SOS_TOKEN = 2\n",
    "EOS_TOKEN = 3\n",
    "init_dict = {'<pad>':PAD_TOKEN,'<unk>':UNK_TOKEN,'<sos>':SOS_TOKEN,'<eos>':EOS_TOKEN}\n",
    "\n",
    "# Collect words from training set\n",
    "words = set()\n",
    "words |= collect_words('trainset.csv')\n",
    "    \n",
    "if os.path.isfile('./dicitonary.pkl') and not COLLECT_WORDS:\n",
    "    print ('Loading collected word dictionary now...')\n",
    "    with open('dicitonary.pkl','rb') as f:\n",
    "        word_dict = pickle.load(f)\n",
    "        f.close()\n",
    "else:\n",
    "    print ('Collecting new word dictionary now...')\n",
    "    word_dict = make_up_word_dictionary(words=words, init_dict=init_dict)\n",
    "    \n",
    "    with open('dicitonary.pkl','wb') as f:\n",
    "        pickle.dump(word_dict, f)\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# num words: 6330\n"
     ]
    }
   ],
   "source": [
    "print ('# num words:', len(word_dict))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Embedding class to save pretrained embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "# from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "class Embedding:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        embedding_path (str): Path where embedding are loaded from (text file).\n",
    "        words (None or list): If not None, only load embedding of the words in\n",
    "            the list.\n",
    "        oov_as_unk (bool): If argument `words` are provided, whether or not\n",
    "            treat words in `words` but not in embedding file as `<unk>`. If\n",
    "            true, OOV will be mapped to the index of `<unk>`. Otherwise,\n",
    "            embedding of those OOV will be randomly initialize and their\n",
    "            indices will be after non-OOV.\n",
    "        lower (bool): Whether or not lower the words.\n",
    "        rand_seed (int): Random seed for embedding initialization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_path=None,\n",
    "                 words=None, oov_as_unk=True, lower=True, rand_seed=524):\n",
    "        self.word_dict = {}\n",
    "        self.index_dict = {}\n",
    "        self.vectors = None\n",
    "        self.lower = lower\n",
    "        \n",
    "        self.extend(embedding_path, words, oov_as_unk)\n",
    "        torch.manual_seed(rand_seed)\n",
    "\n",
    "        if '<pad>' not in self.word_dict:\n",
    "            self.add(\n",
    "                '<pad>', torch.zeros(self.get_dim())\n",
    "            )\n",
    "        \n",
    "        if '<sos>' not in self.word_dict:\n",
    "            t_tensor = torch.rand((1, self.get_dim()), dtype=torch.float)\n",
    "            torch.nn.init.orthogonal_(t_tensor)\n",
    "            self.add(\n",
    "                '<sos>', t_tensor\n",
    "            )\n",
    "            \n",
    "        if '<eos>' not in self.word_dict:\n",
    "            t_tensor = torch.rand((1, self.get_dim()), dtype=torch.float)\n",
    "            torch.nn.init.orthogonal_(t_tensor)\n",
    "            self.add(\n",
    "                '<eos>', t_tensor\n",
    "            )\n",
    "        \n",
    "        if '<unk>' not in self.word_dict:\n",
    "            self.add('<unk>')\n",
    "\n",
    "    def to_word(self, index):\n",
    "        return self.index_dict[index]\n",
    "    \n",
    "    def to_index(self, word):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            word (str)\n",
    "\n",
    "        Return:\n",
    "             index of the word. If the word is not in `words` and not in the\n",
    "             embedding file, then index of `<unk>` will be returned.\n",
    "        \"\"\"\n",
    "        if self.lower:\n",
    "            word = word.lower()\n",
    "\n",
    "        if word not in self.word_dict:\n",
    "            return self.word_dict['<unk>']\n",
    "        else:\n",
    "            return self.word_dict[word]\n",
    "\n",
    "    def get_dim(self):\n",
    "        return self.vectors.shape[1]\n",
    "\n",
    "    def get_vocabulary_size(self):\n",
    "        return self.vectors.shape[0]\n",
    "\n",
    "    def add(self, word, vector=None):\n",
    "        if self.lower:\n",
    "            word = word.lower()\n",
    "\n",
    "        if vector is not None:\n",
    "            vector = vector.view(1, -1)\n",
    "        else:\n",
    "            vector = torch.empty(1, self.get_dim())\n",
    "            torch.nn.init.uniform_(vector)\n",
    "            \n",
    "        self.vectors = torch.cat([self.vectors, vector], 0)\n",
    "        self.index_dict[len(self.word_dict)] = word\n",
    "        self.word_dict[word] = len(self.word_dict)\n",
    "\n",
    "    def extend(self, embedding_path, words, oov_as_unk=True):\n",
    "        \n",
    "        if embedding_path is None:\n",
    "            self._load_w2v_embedding(words)\n",
    "            # self._one_hot_encoding(words) # One-hot encoding version (It can't well-trained)\n",
    "        else:\n",
    "            self._load_embedding(embedding_path, words)\n",
    "\n",
    "        if words is not None and not oov_as_unk:\n",
    "            # initialize word vector for OOV\n",
    "            for word in words:\n",
    "                if self.lower:\n",
    "                    word = word.lower()\n",
    "\n",
    "                if word not in self.word_dict:\n",
    "                    self.index_dict[len(self.word_dict)] = word\n",
    "                    self.word_dict[word] = len(self.word_dict)\n",
    "\n",
    "            oov_vectors = torch.nn.init.uniform_(\n",
    "                torch.empty(len(self.word_dict) - self.vectors.shape[0],\n",
    "                            self.vectors.shape[1]))\n",
    "\n",
    "            self.vectors = torch.cat([self.vectors, oov_vectors], 0)\n",
    "    def _load_w2v_embedding(self, words):\n",
    "        \n",
    "        vectors = []\n",
    "        \n",
    "        for word in words:\n",
    "            \n",
    "            vector = w2v_model[word]\n",
    "            \n",
    "            # skip word not in words if words are provided\n",
    "            if words is not None and word not in words:\n",
    "                continue\n",
    "            elif word not in self.word_dict:\n",
    "                self.index_dict[len(self.word_dict)] = word\n",
    "                self.word_dict[word] = len(self.word_dict)\n",
    "                vectors.append([float(v) for v in vector])\n",
    "\n",
    "        vectors = torch.tensor(vectors)\n",
    "        if self.vectors is not None:\n",
    "            self.vectors = torch.cat([self.vectors, vectors], dim=0)\n",
    "        else:\n",
    "            self.vectors = vectors\n",
    "        \n",
    "    def _one_hot_encoding(self, words):\n",
    "\n",
    "        vectors = []\n",
    "\n",
    "        data_le = pd.DataFrame(words, columns=['Word'])\n",
    "        data_dum = pd.get_dummies(data_le)\n",
    "        \n",
    "        for col in data_dum.columns:\n",
    "            word = col[5:]\n",
    "            self.index_dict[len(self.word_dict)] = word\n",
    "            self.word_dict[word] = len(self.word_dict)\n",
    "            vectors.append([float(row) for row in data_dum[col]])\n",
    "        \n",
    "        vectors = torch.tensor(vectors)\n",
    "        if self.vectors is not None:\n",
    "            self.vectors = torch.cat([self.vectors, vectors], dim=0)\n",
    "        else:\n",
    "            self.vectors = vectors\n",
    "\n",
    "    def _load_embedding(self, embedding_path, words):\n",
    "        if words is not None:\n",
    "            words = set(words)\n",
    "\n",
    "        vectors = []\n",
    "\n",
    "        with open(embedding_path) as fp:\n",
    "\n",
    "            row1 = fp.readline()\n",
    "            # if the first row is not header\n",
    "            if not re.match('^[0-9]+ [0-9]+$', row1):\n",
    "                # seek to 0\n",
    "                fp.seek(0)\n",
    "            # otherwise ignore the header\n",
    "\n",
    "            for i, line in enumerate(fp):\n",
    "                cols = line.rstrip().split(' ')\n",
    "                word = cols[0]\n",
    "\n",
    "                # skip word not in words if words are provided\n",
    "                if words is not None and word not in words:\n",
    "                    continue\n",
    "                elif word not in self.word_dict:\n",
    "                    self.index_dict[len(self.word_dict)] = word\n",
    "                    self.word_dict[word] = len(self.word_dict)\n",
    "                    vectors.append([float(v) for v in cols[1:]])\n",
    "\n",
    "        vectors = torch.tensor(vectors)\n",
    "        if self.vectors is not None:\n",
    "            self.vectors = torch.cat([self.vectors, vectors], dim=0)\n",
    "        else:\n",
    "            self.vectors = vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('./embedding.pkl') and not EMBEDDING_REBUILD:\n",
    "    with open('embedding.pkl','rb') as f:\n",
    "        embedder = pickle.load(f)\n",
    "        f.close()\n",
    "else:\n",
    "    embedder = Embedding(words=words) \n",
    "    \n",
    "    with open('embedding.pkl','wb') as f:\n",
    "        pickle.dump(embedder, f)\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max lenght of key 5\n",
      "\n",
      "Embedder word dictionary:\n",
      "荔     0\n",
      "鲈     1\n",
      "懐     2\n",
      "谇     3\n",
      "娶     4\n",
      "叟     5\n",
      "寺     6\n",
      "良     7\n",
      "梶     8\n",
      "舱     9\n",
      "楨     10\n",
      "緾     11\n",
      "尚     12\n",
      "叱     13\n",
      "概     14\n",
      "逊     15\n",
      "雲     16\n",
      "滾     17\n",
      "順     18\n",
      "媳     19\n",
      "駐     20\n",
      "谧     21\n",
      "鱿     22\n",
      "兖     23\n",
      "蕖     24\n",
      "閉     25\n",
      "颖     26\n",
      "衾     27\n",
      "霉     28\n",
      "價     29\n",
      "谄     30\n",
      "扯     31\n"
     ]
    }
   ],
   "source": [
    "max_key_len = max(len(key) for key in embedder.word_dict.keys())\n",
    "print ('max lenght of key', max_key_len)\n",
    "print ('')\n",
    "print ('Embedder word dictionary:')\n",
    "for key in embedder.word_dict.keys():\n",
    "    padding = max_key_len - len(key)\n",
    "    key_display = key + ' ' * padding\n",
    "    print (key_display, embedder.word_dict[key])\n",
    "    \n",
    "    if embedder.word_dict[key] > 30:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedder index dictionary:\n",
      "0   荔\n",
      "1   鲈\n",
      "2   懐\n",
      "3   谇\n",
      "4   娶\n",
      "5   叟\n",
      "6   寺\n",
      "7   良\n",
      "8   梶\n",
      "9   舱\n",
      "10   楨\n",
      "11   緾\n",
      "12   尚\n",
      "13   叱\n",
      "14   概\n",
      "15   逊\n",
      "16   雲\n",
      "17   滾\n",
      "18   順\n",
      "19   媳\n",
      "20   駐\n",
      "21   谧\n",
      "22   鱿\n",
      "23   兖\n",
      "24   蕖\n",
      "25   閉\n",
      "26   颖\n",
      "27   衾\n",
      "28   霉\n",
      "29   價\n",
      "30   谄\n",
      "31   扯\n"
     ]
    }
   ],
   "source": [
    "print ('Embedder index dictionary:')\n",
    "for key in embedder.index_dict.keys():\n",
    "\n",
    "    print (key, ' ', embedder.index_dict[key])\n",
    "    \n",
    "    if key > 30:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "        \n",
    "def sentence_to_indices(sentence, word_dict):\n",
    "    \"\"\" Convert sentence to its word indices.\n",
    "        We first tokenize the sentence and convert each word into indices.\n",
    "    Args:\n",
    "        sentence (str): One string.\n",
    "    Return:\n",
    "        indices (list of int): List of word indices.\n",
    "    \"\"\"\n",
    "    return [word_dict.to_index(word) for word in sentence.split(' ')]\n",
    "    \n",
    "def get_dataset(data_path, word_dict, n_workers=4):\n",
    "    \"\"\" Load data and return dataset for training and validating.\n",
    "\n",
    "    Args:\n",
    "        data_path (str): Path to the data.\n",
    "    \"\"\"\n",
    "    dataset = pd.read_csv(data_path, dtype=str)\n",
    "\n",
    "    results = [None] * n_workers\n",
    "    with Pool(processes=n_workers) as pool:\n",
    "        for i in range(n_workers):\n",
    "            batch_start = (len(dataset) // n_workers) * i\n",
    "            if i == n_workers - 1:\n",
    "                batch_end = len(dataset)\n",
    "            else:\n",
    "                batch_end = (len(dataset) // n_workers) * (i + 1)\n",
    "            \n",
    "            batch = dataset[batch_start: batch_end]\n",
    "            results[i] = pool.apply_async(preprocess_samples, args=(batch,word_dict))\n",
    "\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "    processed = []\n",
    "    for result in results:\n",
    "        processed += result.get()\n",
    "    return processed\n",
    "\n",
    "def preprocess_samples(dataset, word_dict):\n",
    "    \"\"\" Worker function.\n",
    "\n",
    "    Args:\n",
    "        dataset (list of dict)\n",
    "    Returns:\n",
    "        list of processed dict.\n",
    "    \"\"\"\n",
    "    processed = []\n",
    "    for sample in tqdm(dataset.iterrows(), total=len(dataset)):\n",
    "        processed.append(preprocess_sample(sample[1], word_dict))\n",
    "\n",
    "    return processed\n",
    "\n",
    "def preprocess_sample(data, word_dict):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data (dict)\n",
    "    Returns:\n",
    "        dict\n",
    "    \"\"\"\n",
    "    processed = {}\n",
    "    processed['Sentence'] = sentence_to_indices(data['Sentence'], word_dict)\n",
    "    processed['Label'] = sentence_to_indices(data['Label'], word_dict)\n",
    "    \n",
    "    return processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Start processing trainset...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[INFO] Start processing validset...\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('[INFO] Start processing trainset...')\n",
    "train = get_dataset('trainset.csv', embedder, n_workers=4)\n",
    "print('[INFO] Start processing validset...')\n",
    "valid = get_dataset('validset.csv', embedder, n_workers=4)\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Preserve the testset order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_with_no_multiprocessing(data_path, word_dict):\n",
    "    \n",
    "    dataset = pd.read_csv(data_path, dtype=str)\n",
    "    trange = tqdm(dataset.iterrows(), total=len(dataset))\n",
    "    \n",
    "    processed = []\n",
    "    \n",
    "    for i, (sample) in enumerate(trange):\n",
    "        processed.append(preprocess_sample(sample[1], word_dict))\n",
    "        \n",
    "    return processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Start processing testset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fdb07c4e1934538bdf28d058a5f78bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('[INFO] Start processing testset...')\n",
    "test = get_dataset_with_no_multiprocessing('testset.csv', embedder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class SentenceDataset(Dataset):\n",
    "    def __init__(self, data, pad_idx, max_len = 300):\n",
    "        self.data = data\n",
    "        self.pad_idx = pad_idx\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "    def pad_seq(self, seq, max_length):\n",
    "        '''\n",
    "        Pad a with the PAD symbol\n",
    "        '''\n",
    "        seq += [self.pad_idx]*(max_length - len(seq))\n",
    "        return seq\n",
    "        \n",
    "    def collate_fn(self, datas):\n",
    "        \n",
    "        input_seqs = []\n",
    "        target_seqs = []\n",
    "            \n",
    "        for data in datas:\n",
    "            \n",
    "            sentence = data['Sentence']\n",
    "            target = data['Label']\n",
    "            \n",
    "            input_seqs.append(sentence)\n",
    "            target_seqs.append(target)\n",
    "            \n",
    "            # padding sentences to make them in same length\n",
    "            # if len(sentence) > max_len:\n",
    "            #     sentence = sentence[:max_len]\n",
    "            # else:\n",
    "            #     sentence = sentence+[self.pad_idx]*(max_len-len(sentence))\n",
    "            #     \n",
    "            # sent_len.append(len(sentence))\n",
    "            \n",
    "        # Zip into pairs, sort by length (descending), unzip\n",
    "        seq_pairs = sorted(zip(input_seqs, target_seqs), key=lambda p: len(p[0]), reverse=True)\n",
    "        input_seqs, target_seqs = zip(*seq_pairs)\n",
    "    \n",
    "        # For input and target sequences, get array of lengths and pad with 0s to max length\n",
    "        input_lengths = [len(s) for s in input_seqs]\n",
    "        input_padded = [self.pad_seq(s, max(input_lengths)) for s in input_seqs]\n",
    "        target_lengths = [len(s) for s in target_seqs]\n",
    "        target_padded = [self.pad_seq(s, max(target_lengths)) for s in target_seqs]\n",
    "\n",
    "        # Turn padded arrays into (batch_size x max_len) tensors, transpose into (max_len x batch_size)\n",
    "        input_var = Variable(torch.LongTensor(input_padded)).transpose(0, 1)\n",
    "        target_var = Variable(torch.LongTensor(target_padded)).transpose(0, 1)\n",
    "        \n",
    "        return input_var, input_lengths, target_var, target_lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index of <pad> in word_dict: 6326\n"
     ]
    }
   ],
   "source": [
    "pad_idx = embedder.word_dict['<pad>']\n",
    "print ('index of <pad> in word_dict:', pad_idx)\n",
    "trainData = SentenceDataset(train, pad_idx)\n",
    "validData = SentenceDataset(valid, pad_idx)\n",
    "testData = SentenceDataset(test, pad_idx)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import random\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_mask(sequence_length, max_len=None):\n",
    "    if max_len is None:\n",
    "        max_len = sequence_length.data.max()\n",
    "    batch_size = sequence_length.size(0)\n",
    "    seq_range = torch.range(0, max_len - 1).long()\n",
    "    seq_range_expand = seq_range.unsqueeze(0).expand(batch_size, max_len)\n",
    "    seq_range_expand = Variable(seq_range_expand)\n",
    "    if sequence_length.is_cuda:\n",
    "        seq_range_expand = seq_range_expand.cuda()\n",
    "    seq_length_expand = (sequence_length.unsqueeze(1)\n",
    "                         .expand_as(seq_range_expand))\n",
    "    return seq_range_expand < seq_length_expand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_cross_entropy(logits, target, length):\n",
    "    length = Variable(torch.LongTensor(length)).cuda()\n",
    "\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        logits: A Variable containing a FloatTensor of size\n",
    "            (batch, max_len, num_classes) which contains the\n",
    "            unnormalized probability for each class.\n",
    "        target: A Variable containing a LongTensor of size\n",
    "            (batch, max_len) which contains the index of the true\n",
    "            class for each corresponding step.\n",
    "        length: A Variable containing a LongTensor of size (batch,)\n",
    "            which contains the length of each data in a batch.\n",
    "    Returns:\n",
    "        loss: An average loss value masked by the length.\n",
    "    \"\"\"\n",
    "\n",
    "    # logits_flat: (batch * max_len, num_classes)\n",
    "    logits_flat = logits.view(-1, logits.size(-1))\n",
    "    # log_probs_flat: (batch * max_len, num_classes)\n",
    "    log_probs_flat = nn.functional.log_softmax(logits_flat)\n",
    "    # target_flat: (batch * max_len, 1)\n",
    "    target_flat = target.view(-1, 1)\n",
    "    # losses_flat: (batch * max_len, 1)\n",
    "    losses_flat = -torch.gather(log_probs_flat, dim=1, index=target_flat)\n",
    "    # losses: (batch, max_len)\n",
    "    losses = losses_flat.view(*target.size())\n",
    "    # mask: (batch, max_len)\n",
    "    mask = sequence_mask(sequence_length=length, max_len=target.size(1))\n",
    "    losses = losses * mask.float()\n",
    "    loss = losses.sum() / length.float().sum()\n",
    "    return loss\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding, output_size):\n",
    "        \"\"\"Define layers for a vanilla rnn encoder\"\"\"\n",
    "        super(SimpleEncoder, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding = embedding\n",
    "        self.hidden_size = output_size\n",
    "        self.num_layers = GRU_NUM_LAYERS\n",
    "        self.dropout = GRU_DROPOUT_RATE # Use it when num_layers > 1\n",
    "        \n",
    "        if self.num_layers > 1:\n",
    "            self.gru = nn.GRU(self.embedding.embedding_dim, \n",
    "                              self.hidden_size,\n",
    "                              num_layers=self.num_layers,\n",
    "                              dropout=self.dropout,\n",
    "                              bidirectional=True,\n",
    "                              batch_first=True)\n",
    "        else:\n",
    "            self.gru = nn.GRU(self.embedding.embedding_dim, \n",
    "                              self.hidden_size,\n",
    "                              bidirectional=True,\n",
    "                              batch_first=True)\n",
    "        if INIT_GRU:\n",
    "            for name, param in self.gru.named_parameters():\n",
    "                if 'bias' in name:\n",
    "                     nn.init.constant_(param, 0.0)\n",
    "                elif 'weight_ih' in name:\n",
    "                     nn.init.kaiming_normal_(param)\n",
    "                elif 'weight_hh' in name:\n",
    "                     nn.init.orthogonal_(param)\n",
    "                        \n",
    "#         self.dropped = nn.Sequential(\n",
    "#             nn.Dropout(0.1),  # drop 50% of the neuron\n",
    "#             # nn.ReLU(),\n",
    "#             nn.Linear(self.hidden_size, 300),\n",
    "#         )\n",
    "                        \n",
    "    def forward(self, input_seqs, input_lengths, hidden=None):\n",
    "                                              # input_seqs's shape = max_len x batch_size\n",
    "        embedded = self.embedding(input_seqs) # embedded's shape = max_len x batch_size x embedding_size(300) \n",
    "        packed = pack_padded_sequence(embedded, input_lengths)\n",
    "        packed_outputs, hidden = self.gru(packed, hidden)\n",
    "        outputs, output_lengths = pad_packed_sequence(packed_outputs)\n",
    "\n",
    "        # discommit if bid = true\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
    "        \n",
    "        return outputs, hidden\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDecoder(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, output_size, embedding, max_length, teacher_forcing_ratio, sos_id, eos_id, use_cuda, dropout_rate):\n",
    "        \"\"\"Define layers for a vanilla rnn decoder\"\"\"\n",
    "        super(SimpleDecoder, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = GRU_NUM_LAYERS\n",
    "        self.dropout = GRU_DROPOUT_RATE\n",
    "        \n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        if self.num_layers > 1:\n",
    "            self.gru = nn.GRU(self.embedding.embedding_dim, \n",
    "                              self.hidden_size,\n",
    "                              num_layers=self.num_layers,\n",
    "                              dropout=self.dropout\n",
    "                              )\n",
    "        else:\n",
    "            self.gru = nn.GRU(self.embedding.embedding_dim, \n",
    "                      self.hidden_size)\n",
    "        \n",
    "        if INIT_GRU:\n",
    "            for name, param in self.gru.named_parameters():\n",
    "                if 'bias' in name:\n",
    "                     nn.init.constant_(param, 0.0)\n",
    "                elif 'weight_ih' in name:\n",
    "                     nn.init.kaiming_normal_(param)\n",
    "                elif 'weight_hh' in name:\n",
    "                     nn.init.orthogonal_(param)\n",
    "                        \n",
    "        self.out = nn.Linear(hidden_size, self.output_size)\n",
    "        self.log_softmax = nn.LogSoftmax()  # work with NLLLoss = CrossEntropyLoss\n",
    "\n",
    "        self.max_length = max_length\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "        self.sos_id = sos_id\n",
    "        self.eos_id = eos_id\n",
    "        self.use_cuda = use_cuda\n",
    "\n",
    "    def forward_step(self, inputs, hidden):\n",
    "        # inputs: (time_steps=1, batch_size)\n",
    "        BEF_inputs = inputs\n",
    "        BEF_hidden = hidden\n",
    "\n",
    "        batch_size = inputs.size(1)\n",
    "        embedded = self.embedding(inputs)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        embedded.view(1, batch_size, self.hidden_size)  # S = T(1) x B x N\n",
    "        rnn_output, hidden = self.gru(embedded, hidden)  # S = T(1) x B x H\n",
    "        rnn_output = rnn_output.squeeze(0)  # squeeze the time dimension B x H \n",
    "        linear_output = self.out(rnn_output)\n",
    "        output = self.log_softmax(linear_output) # S = B x O\n",
    "        if SAVE_tstep == 1:\n",
    "            for target in SAVE_target:\n",
    "                folder = open(SAVE_tstep_route+target+str(cur_epoch)+'-'+str(cur_tstep)+'.pkl','wb')\n",
    "                pickle.dump(model.state_dict().get(target).cpu().numpy(), folder)\n",
    "                folder.close()\n",
    "            folder = open(SAVE_tstep_route+'output'+str(cur_epoch)+'-'+str(cur_tstep)+'.pkl','wb')\n",
    "            pickle.dump(output.cpu().detach().numpy(),folder)\n",
    "            folder.close()\n",
    "            folder = open(SAVE_tstep_route+'decoderRNN_AFT_output'+str(cur_epoch)+'-'+str(cur_tstep)+'.pkl','wb')\n",
    "            pickle.dump(rnn_output.cpu().detach().numpy(),folder)\n",
    "            folder.close()\n",
    "            folder = open(SAVE_tstep_route+'decoderRNN_AFT_hidden'+str(cur_epoch)+'-'+str(cur_tstep)+'.pkl','wb')\n",
    "            pickle.dump(hidden.cpu().detach().numpy(),folder)\n",
    "            folder.close()\n",
    "            folder = open(SAVE_tstep_route+'decoderRNN_BEF_inputs'+str(cur_epoch)+'-'+str(cur_tstep)+'.pkl','wb')\n",
    "            pickle.dump(embedded.cpu().detach().numpy(),folder)\n",
    "            folder.close()\n",
    "            folder = open(SAVE_tstep_route+'decoderRNN_BEF_hidden'+str(cur_epoch)+'-'+str(cur_tstep)+'.pkl','wb')\n",
    "            pickle.dump(BEF_hidden.cpu().detach().numpy(),folder)\n",
    "            folder.close()\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def forward(self, context_vector, targets, target_lengths):\n",
    "\n",
    "        # Prepare variable for decoder on time_step_0\n",
    "        # [['<sos>'], ['<sos>'], ..., ['<sos>'], ['<sos>']]\n",
    "        target_vars = targets\n",
    "        batch_size = context_vector.size(1)\n",
    "        decoder_input = Variable(torch.LongTensor([[self.sos_id] * batch_size]))\n",
    "\n",
    "        # Pass the context vector \n",
    "        # (By identically pass)\n",
    "        decoder_hidden = []\n",
    "        for i in range(0, self.num_layers*2, 2):\n",
    "            decoder_hidden.append(context_vector[i] + context_vector[i+1])\n",
    "\n",
    "        # commit above if bid = True\n",
    "        # for i in range(0, self.num_layers, 1):\n",
    "        #     decoder_hidden.append(context_vector[i])\n",
    "\n",
    "        decoder_hidden = torch.stack(decoder_hidden, dim=0)\n",
    "\n",
    "        max_target_length = max(target_lengths)\n",
    "        decoder_outputs = Variable(torch.zeros(\n",
    "            max_target_length,\n",
    "            batch_size,\n",
    "            self.output_size\n",
    "        ))  # (time_steps, batch_size, vocab_size)\n",
    "\n",
    "        if self.use_cuda:\n",
    "            decoder_input = decoder_input.cuda()\n",
    "            decoder_outputs = decoder_outputs.cuda()\n",
    "\n",
    "        use_teacher_forcing = True if random.random() > self.teacher_forcing_ratio else False\n",
    "\n",
    "        # Unfold the decoder RNN on the time dimension\n",
    "        for t in range(max_target_length):\n",
    "\n",
    "            decoder_outputs_on_t, decoder_hidden = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs[t] = decoder_outputs_on_t\n",
    "            if use_teacher_forcing:\n",
    "                decoder_input = target_vars[t].unsqueeze(0)\n",
    "            else:\n",
    "                decoder_input = self._decode_to_index(decoder_outputs_on_t)\n",
    "            \n",
    "        return decoder_outputs, decoder_hidden\n",
    "\n",
    "    def evaluation(self, context_vector):\n",
    "        batch_size = context_vector.size(1) # get the batch size\n",
    "        decoder_input = Variable(torch.LongTensor([[self.sos_id] * batch_size]))\n",
    "        \n",
    "        decoder_hidden = []\n",
    "        for i in range(0, self.num_layers*2, 2):\n",
    "            decoder_hidden.append(context_vector[i] + context_vector[i+1])\n",
    "        decoder_hidden = torch.stack(decoder_hidden, dim=0)\n",
    "\n",
    "        decoder_outputs = Variable(torch.zeros(\n",
    "            self.max_length,\n",
    "            batch_size,\n",
    "            self.output_size\n",
    "        ))  # (time_steps, batch_size, vocab_size)\n",
    "\n",
    "        if self.use_cuda:\n",
    "            decoder_input = decoder_input.cuda()\n",
    "            decoder_outputs = decoder_outputs.cuda()\n",
    "\n",
    "        # Unfold the decoder RNN on the time dimension\n",
    "        for t in range(self.max_length):\n",
    "            global cur_tstep\n",
    "            cur_tstep = t\n",
    "            decoder_outputs_on_t, decoder_hidden = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs[t] = decoder_outputs_on_t\n",
    "            decoder_input = self._decode_to_index(decoder_outputs_on_t)  # select the former output as input\n",
    "\n",
    "        return self._decode_to_indices(decoder_outputs)\n",
    "\n",
    "    def _decode_to_index(self, decoder_output):\n",
    "        \"\"\"\n",
    "        evaluate on the logits, get the index of top1\n",
    "        :param decoder_output: S = B x V or T x V\n",
    "        \"\"\"\n",
    "        value, index = torch.topk(decoder_output, 1)\n",
    "        index = index.transpose(0, 1)  # S = 1 x B, 1 is the index of top1 class\n",
    "        if self.use_cuda:\n",
    "            index = index.cuda()\n",
    "        return index\n",
    "\n",
    "    def _decode_to_indices(self, decoder_outputs):\n",
    "        \"\"\"\n",
    "        Evaluate on the decoder outputs(logits), find the top 1 indices.\n",
    "        Please confirm that the model is on evaluation mode if dropout/batch_norm layers have been added\n",
    "        :param decoder_outputs: the output sequence from decoder, shape = T x B x V \n",
    "        \"\"\"\n",
    "        decoded_indices = []\n",
    "        batch_size = decoder_outputs.size(1)\n",
    "        decoder_outputs = decoder_outputs.transpose(0, 1)  # S = B x T x V\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            top_ids = self._decode_to_index(decoder_outputs[b])\n",
    "            decoded_indices.append(top_ids.data[0])\n",
    "        return decoded_indices\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input_vars, input_lengths, targets, target_lengths):\n",
    "        encoder_outputs, encoder_hidden = self.encoder.forward(input_vars, input_lengths)\n",
    "        decoder_outputs, decoder_hidden = self.decoder.forward(context_vector=encoder_hidden, targets=targets, target_lengths=target_lengths)\n",
    "        return decoder_outputs, decoder_hidden\n",
    "\n",
    "    def evaluation(self, input_vars, input_lengths):\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_vars, input_lengths)\n",
    "        decoded_sentence = self.decoder.evaluation(context_vector=encoder_hidden)\n",
    "        return decoded_sentence\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import trange\n",
    "import json\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Specify the training device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print (device)\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Define epochs and iterations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def _run_epoch(epoch, embedding, training):\n",
    "    \n",
    "    global x_list\n",
    "    global iter_counter\n",
    "    7\n",
    "    model.train(training)\n",
    "    if training:\n",
    "        description = 'Train'\n",
    "        dataset = trainData\n",
    "        shuffle = True\n",
    "    else:\n",
    "        description = 'Valid'\n",
    "        dataset = validData\n",
    "        shuffle = False\n",
    "    dataloader = DataLoader(dataset=dataset,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=shuffle,\n",
    "                            collate_fn=dataset.collate_fn,\n",
    "                            num_workers=4)\n",
    "\n",
    "    trange = tqdm(enumerate(dataloader), total=len(dataloader), desc=description)\n",
    "    loss = 0\n",
    "\n",
    "    for i, (x, x_lengths, y, y_lengths) in trange:\n",
    "        iter_counter += 1\n",
    "        o_labels, batch_loss = _run_iter(x, x_lengths, y, y_lengths)\n",
    "        \n",
    "        if training:\n",
    "            opt.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            opt.step()\n",
    "             \n",
    "        loss += batch_loss.item()\n",
    "        acc = 0\n",
    "        \n",
    "        trange.set_postfix(\n",
    "            loss = loss / (i + 1), acc=acc)\n",
    "\n",
    "        if training:\n",
    "            if iter_counter % SAVE_ITER_interval == 0 and SAVE_OUTPUT == 1:\n",
    "                output = open(OUTPUT_route + 'iters.' + str(iter_counter) + '.pkl', 'wb')\n",
    "                pickle.dump(model.state_dict().get('decoder.out.weight').cpu().numpy(), output)\n",
    "                output.close()\n",
    "    \n",
    "    if training:\n",
    "        history['train'].append({'acc': 0, 'loss':loss / len(trange)})\n",
    "            \n",
    "    else:\n",
    "        history['valid'].append({'acc': 0, 'loss':loss / len(trange)})\n",
    "\n",
    "\n",
    "# ??\n",
    "def get_loss(decoder_outputs, targets):\n",
    "    b = decoder_outputs.size(1)\n",
    "    t = decoder_outputs.size(0)\n",
    "    targets = targets.contiguous().view(-1)  # S = (B*T)\n",
    "    decoder_outputs = decoder_outputs.view(b * t, -1)  # S = (B*T) x V\n",
    "    return criteria(decoder_outputs, targets)\n",
    "        \n",
    "def _run_iter(x, x_lengths, y, y_lengths):\n",
    "    sentences = x.to(device)\n",
    "    sentence_lengths = x_lengths\n",
    "    labels = y.to(device)\n",
    "    label_lengths = y_lengths\n",
    "    \n",
    "    o_labels, hidden = model(sentences, sentence_lengths, labels, label_lengths)\n",
    "    #l_loss = get_loss(o_labels, labels)\n",
    "    \n",
    "    l_loss = masked_cross_entropy(\n",
    "        o_labels.transpose(0, 1).contiguous(), # -> batch x seq\n",
    "        labels.transpose(0, 1).contiguous(), # -> batch x seq\n",
    "        label_lengths\n",
    "    )\n",
    "    return o_labels, l_loss\n",
    "\n",
    "def save(epoch):\n",
    "    \n",
    "    splitted_path = os.path.split(MODEL_SAVE_PATH)\n",
    "    model_path = splitted_path[0] + '/' + splitted_path[1] \n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "    \n",
    "    torch.save(model.state_dict(), MODEL_SAVE_PATH + 'model.pkl.' + str(epoch))\n",
    "    with open(MODEL_SAVE_PATH + 'history.json', 'w') as f:\n",
    "        json.dump(history, f, indent=4)\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Choose a proper criteria and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(datas):\n",
    "    return max([len(data['Sentence']) for data in datas])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New encoder output size (decoder hidden size): 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "SOS_TOKEN = embedder.word_dict['<sos>']\n",
    "EOS_TOKEN = embedder.word_dict['<eos>']\n",
    "\n",
    "train_max_length = get_max_len(trainData)\n",
    "valid_max_length = get_max_len(validData)\n",
    "test_max_length = get_max_len(testData)\n",
    "all_max_length = max(train_max_length, valid_max_length, test_max_length)\n",
    "\n",
    "use_cuda = (device == torch.device('cuda:0'))\n",
    "\n",
    "embedding = nn.Embedding(embedder.get_vocabulary_size(), embedder.get_dim())\n",
    "embedding.weight = torch.nn.Parameter(embedder.vectors)\n",
    "\n",
    "# One-hot encoding changes the vector dimension.\n",
    "ENCODER_OUTPUT_SIZE = embedder.vectors[0].size(0)\n",
    "DECODER_HIDDEN_SIZE = ENCODER_OUTPUT_SIZE\n",
    "print ('New encoder output size (decoder hidden size):', ENCODER_OUTPUT_SIZE)\n",
    "\n",
    "encoder = SimpleEncoder(vocab_size=embedder.get_vocabulary_size(),\n",
    "                        embedding=embedding,\n",
    "                        output_size=ENCODER_OUTPUT_SIZE)\n",
    "\n",
    "decoder = SimpleDecoder(hidden_size=DECODER_HIDDEN_SIZE,\n",
    "                        output_size=embedder.get_vocabulary_size(),\n",
    "                        embedding=embedding,\n",
    "                        max_length=all_max_length,\n",
    "                        teacher_forcing_ratio=TEACHER_FORCING_RATIO,\n",
    "                        sos_id=SOS_TOKEN,\n",
    "                        eos_id=EOS_TOKEN,\n",
    "                        use_cuda=use_cuda,\n",
    "                        dropout_rate=EMBEDDING_DROPOUT_RATE)\n",
    "\n",
    "if use_cuda:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "\n",
    "model = Seq2Seq(encoder=encoder,\n",
    "                  decoder=decoder)\n",
    "if TRAINING_RESUME:\n",
    "    model.load_state_dict(torch.load(MODEL_SAVE_PATH + 'model.pkl.{}'.format(RESUME_EPOCH)))\n",
    "    \n",
    "opt = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criteria = torch.nn.NLLLoss(ignore_index=pad_idx, size_average=True)\n",
    "\n",
    "model.to(device)\n",
    "max_epoch = MAX_EPOCH\n",
    "history = {'train':[],'valid':[]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm as tqdm\n",
    "import pickle\n",
    "# saving hs from coder within each epoch (route)\n",
    "SAVE_epoch_coder = 1\n",
    "ENCODER_last_hs = 'encoder_last_hs/'\n",
    "DECODER_last_hs = 'decoder_last_hs/'\n",
    "# saving output weight (route)\n",
    "SAVE_OUTPUT = 1\n",
    "SAVE_ITER_interval = 100\n",
    "OUTPUT_route = 'output_100/'\n",
    "\n",
    "iter_counter = 0\n",
    "for epoch in range(max_epoch):\n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    _run_epoch(epoch, embedding, True)\n",
    "\n",
    "    # saving hs from coder within each epoch\n",
    "    if SAVE_epoch_coder:\n",
    "        output = open(ENCODER_last_hs + 'epoch.' + str(epoch) + '.pkl','wb')\n",
    "        pickle.dump(model.state_dict().get('encoder.gru.weight_hh_l'+str(GRU_NUM_LAYERS-1)).cpu().numpy(),output)\n",
    "        output.close()\n",
    "        output = open(DECODER_last_hs + 'epoch.' + str(epoch) + '.pkl','wb')\n",
    "        pickle.dump(model.state_dict().get('decoder.gru.weight_hh_l'+str(GRU_NUM_LAYERS-1)).cpu().numpy(),output)\n",
    "        output.close()\n",
    "        \n",
    "    _run_epoch(epoch, embedding, False)\n",
    "    save(epoch)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Plot training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 score  [0, 20]\n"
     ]
    }
   ],
   "source": [
    "with open(MODEL_SAVE_PATH + 'history.json', 'r') as f:\n",
    "    history = json.loads(f.read())\n",
    "    \n",
    "train_loss = [l['loss'] for l in history['train']]\n",
    "valid_loss = [l['loss'] for l in history['valid']]\n",
    "train_acc = [l['acc'] for l in history['train']]\n",
    "valid_acc = [l['acc'] for l in history['valid']]\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.title('Loss')\n",
    "plt.plot(train_loss, label='train')\n",
    "plt.plot(valid_loss, label='valid')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.title('Acc')\n",
    "plt.plot(train_acc, label='train')\n",
    "plt.plot(valid_acc, label='valid')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('Best F1 score ', max([[l['acc'], idx] for idx, l in enumerate(history['valid'])]))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser_words(word_list):\n",
    "    i = 0\n",
    "    sentence = ''\n",
    "    while i < len(word_list):\n",
    "        if word_list[i] == '<' and i+2 < len(word_list):\n",
    "            sentence = sentence + word_list[i] + word_list[i+1] + word_list[i+2]\n",
    "            \n",
    "            if word_list[i+1] == 'eos':\n",
    "                break\n",
    "            else:\n",
    "                i = i + 3\n",
    "        else:\n",
    "            sentence = sentence + word_list[i]\n",
    "            i = i + 1\n",
    "\n",
    "        sentence = sentence + ' '\n",
    "\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read datas with only control signal = 10~15\n",
    "import pickle\n",
    "file = open('con_sig_dataset_1_n1000.pkl', 'rb')\n",
    "con_sig_dataset = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(con_sig_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0046879b6f14390bd4ec99e54eb5b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Test', max=1, style=ProgressStyle(description_width='initial'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:55: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0 - precision: 0.9965\n",
      "\n",
      "all - precision: 0.9965\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "checkpoint_epoch= 20\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH + 'model.pkl.{}'.format(checkpoint_epoch)))\n",
    "model.train(False)\n",
    "\n",
    "# loadout settings\n",
    "SAVE_tstep = 1\n",
    "SAVE_tstep_route = 'evaluate_signal_1/'\n",
    "SAVE_target = ['decoder.gru.weight_ih_l3',\n",
    "'decoder.gru.weight_hh_l3',\n",
    "'decoder.gru.bias_ih_l3',\n",
    "'decoder.gru.bias_hh_l3']\n",
    "\n",
    "description = 'Test'\n",
    "dataset = con_sig_dataset\n",
    "shuffle = False\n",
    "\n",
    "dataloader = DataLoader(dataset=dataset,\n",
    "                        batch_size=len(con_sig_dataset),\n",
    "                        shuffle=shuffle,\n",
    "                        collate_fn=dataset.collate_fn,\n",
    "                        num_workers=4)\n",
    "\n",
    "trange = tqdm(enumerate(dataloader), total=len(dataloader), desc=description)\n",
    "test_loss = 0\n",
    "originals = []\n",
    "results = []\n",
    "gts = []\n",
    "all_corrects = 0\n",
    "all_queries = 0\n",
    "\n",
    "for i, (x, x_lengths, y, y_lengths) in trange:\n",
    "    if i == 2:\n",
    "        break\n",
    "    cur_epoch = i\n",
    "    cur_tstep = 0\n",
    "    precisions = []\n",
    "    batch_corrects = 0\n",
    "    batch_queries = 0\n",
    "    \n",
    "    x = x.to(device)\n",
    "    batch_decoded_indices = model.evaluation(input_vars=x, input_lengths=x_lengths) # batch_size x max_len\n",
    "    \n",
    "    if SAVE_tstep == 1:\n",
    "        output = open(SAVE_tstep_route+'X.'+str(cur_epoch)+'.pkl','wb')\n",
    "        pickle.dump(x.cpu().numpy(), output)\n",
    "        output.close()\n",
    "        \n",
    "    for sent_idx, decoded_indices in enumerate(batch_decoded_indices):\n",
    "        \n",
    "        # Original sentence\n",
    "        original = []\n",
    "        input_sentence = x.transpose(0,1)[sent_idx].data.cpu().numpy()\n",
    "        \n",
    "        for index in input_sentence:\n",
    "            original_word = embedder.to_word(index)\n",
    "            \n",
    "            if original_word == '<pad>':\n",
    "                break\n",
    "                \n",
    "            original.append(original_word)\n",
    "            \n",
    "        #print ('input', input_sentence)\n",
    "        #print ('input-original', original)\n",
    "        #print ('input\\'s shape', input_sentence.shape)\n",
    "        \n",
    "        eos_pos = original.index('<eos>')\n",
    "        query_pairs = original[eos_pos+1:]\n",
    "        \n",
    "        if '<pad>' in query_pairs:\n",
    "            pad_pos = query_pairs.index('<pad>')\n",
    "            query_pairs = query_pairs[:pad_pos]\n",
    "            \n",
    "        num_query = len(query_pairs) // 2\n",
    "        \n",
    "        # Ground truth sentence\n",
    "        gt = []\n",
    "        target_sentence = y.transpose(0,1)[sent_idx].data.cpu().numpy()\n",
    "        \n",
    "        for _index in target_sentence:   \n",
    "            gt.append(embedder.to_word(_index))\n",
    "            \n",
    "        #print ('target', target_sentence)\n",
    "        #print ('target-gt', gt)\n",
    "        #print ('target\\'s shape', target_sentence.shape)\n",
    "        \n",
    "        # predicted sentence\n",
    "        decoded_indices = decoded_indices.data.cpu().numpy()\n",
    "        result = []\n",
    "        for decoded_index in decoded_indices:\n",
    "            int_index = int(decoded_index)\n",
    "            decoded_word = embedder.to_word(int_index)\n",
    "            result.append(decoded_word)\n",
    "            \n",
    "            if decoded_word == '<eos>':\n",
    "                break\n",
    "        \n",
    "        #print ('predicted', decoded_indices)\n",
    "        #print ('predicted-result', result)\n",
    "        #print ('predicted\\'s shape', decoded_indices.shape)\n",
    "        \n",
    "        #print (query_pairs)\n",
    "        \n",
    "        for j in range(0, len(query_pairs), 2):\n",
    "            pos = int(query_pairs[j])\n",
    "            word = query_pairs[j+1]\n",
    "            \n",
    "            if pos < len(result):\n",
    "                if result[pos] == word:\n",
    "                    batch_corrects += 1\n",
    "                \n",
    "            batch_queries += 1\n",
    "        \n",
    "        # print ('input   => %s\\npredict => %s\\n' % (parser_words(original), parser_words(result)))\n",
    "        \n",
    "        results.append(result)\n",
    "        \n",
    "        originals.append(original)\n",
    "        gts.append(gt)\n",
    "        \n",
    "    all_corrects = all_corrects + batch_corrects\n",
    "    all_queries = all_queries + batch_queries\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        print ('batch', i, '- precision:', batch_corrects / batch_queries)\n",
    "\n",
    "output = open(SAVE_tstep_route+'results.'+str(cur_epoch)+'.pkl','wb')\n",
    "pickle.dump(results, output)\n",
    "output.close()\n",
    "print ('all - precision:', all_corrects / all_queries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('all - precision:', all_corrects / all_queries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print ('input   => %s\\npredict => %s\\nground truth => %s\\n' % (parser_words(originals[i]), parser_words(results[i]), parser_words(gts[i])))\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Write out Output csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_orderd_results = []\n",
    "\n",
    "trange = tqdm(enumerate(testData), total=len(testData), desc='Reorder')\n",
    "\n",
    "for k, (data) in enumerate(trange):\n",
    "    \n",
    "    # print ('k:', k)\n",
    "    test_original = []\n",
    "    \n",
    "    for index in testData[k]['Sentence']:\n",
    "        test_original.append(embedder.to_word(index))\n",
    "\n",
    "    row_idx = 0\n",
    "    # print (test_original)\n",
    "    \n",
    "    for l, origin in enumerate(originals):\n",
    "        hit = True\n",
    "        \n",
    "        if len(test_original) == len(origin):\n",
    "            for i in range(len(test_original)):\n",
    "                if test_original[i] != origin[i]:\n",
    "                    hit = False\n",
    "        else:\n",
    "            hit = False\n",
    "        \n",
    "        if hit:\n",
    "            row_idx = l\n",
    "            break\n",
    "    \n",
    "    if not hit:\n",
    "        print ('Not found', data)\n",
    "    # print (originals[k])\n",
    "    # print (originals[row_idx])\n",
    "    \n",
    "    original_orderd_results.append(results[row_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../hw2.1-1.txt', 'w') as outfile:\n",
    "    \n",
    "    trange = tqdm(enumerate(original_orderd_results), total=len(original_orderd_results), desc='WriteBack')\n",
    "    \n",
    "    for j, (_row) in enumerate(trange):\n",
    "        line = parser_words(original_orderd_results[j])\n",
    "        line = line.strip().upper()\n",
    "        line = line + '\\n'\n",
    "        outfile.writelines(line)\n",
    "        \n",
    "    outfile.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
